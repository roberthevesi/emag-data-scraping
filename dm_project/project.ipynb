{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- 1. First Topic: Web Scraping ---------------------\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.emag.ro/search/aliexpress/p1'\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "product_links = soup.find_all('a', class_='card-v2-title semibold mrg-btm-xxs js-product-url')\n",
    "\n",
    "# Raw html content of the page\n",
    "# print(soup)\n",
    "for link in product_links:\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_from_html(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    scripts = soup.find_all('script')\n",
    "    for script in scripts:\n",
    "        if 'EM.product_id' in script.text:\n",
    "            product_id_search = re.search(r'EM.productDiscountedPrice\\s=\\s([0-9.]+);', script.text)\n",
    "            if product_id_search:\n",
    "                return float(product_id_search.group(1))\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_reviews_by_url(product_url):\n",
    "    # remove potential '?' at the end of the url\n",
    "    if product_url.endswith('?'):\n",
    "        product_url = product_url[:-1]\n",
    "\n",
    "    # remove potential '#used-products' at the end of the url\n",
    "    if product_url.endswith('#used-products'):\n",
    "        product_url = product_url[:-len('#used-products')]\n",
    "\n",
    "    # check for potentially missing slash at the very end\n",
    "    if not product_url.endswith('/'):\n",
    "        product_url += '/'\n",
    "\n",
    "    # --------------------- endpoint URL ---------------------\n",
    "\n",
    "    substr_to_remove = 'https://www.emag.ro/'\n",
    "    endpoint_url = 'https://www.emag.ro/product-feedback/'\n",
    "    endpoint_url += product_url.replace(substr_to_remove, '')\n",
    "    endpoint_url += 'reviews/list'\n",
    "\n",
    "    # --------------------- GET request ---------------------\n",
    "\n",
    "    product_response = requests.get(product_url)\n",
    "    product_html = product_response.text\n",
    "    product_soup = BeautifulSoup(product_html, 'html.parser')\n",
    "\n",
    "    # --------------------- number of reviews ---------------------\n",
    "\n",
    "    # get the number of reviews. e.g. for 256 we iterate 26 times, for 5 we iterate 1 time\n",
    "    # res = product_soup.find_all('p', class_='small semibold font-size-sm text-muted')\n",
    "    # reviews_number = re.search(r'\\d+', str(res[0])).group()\n",
    "\n",
    "    # ^^^^^ this approach got dumped because it was only working for products \n",
    "    #       that actually had any number of reviews\n",
    "\n",
    "    offset = 0\n",
    "\n",
    "    params = {\n",
    "        \"source_id\": 7,\n",
    "        \"page[limit]\": 10,\n",
    "        \"page[offset]\": offset,\n",
    "        \"sort[created]\": \"desc\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(endpoint_url, params=params)\n",
    "    data = response.json()\n",
    "    # print(data)\n",
    "    reviews_number = data['reviews']['count']\n",
    "    reviews_number = int(reviews_number)\n",
    "\n",
    "    if reviews_number <= 0:\n",
    "        return []\n",
    "\n",
    "    # --------------------- product title ---------------------\n",
    "\n",
    "    product_title = product_soup.find('h1', class_='page-title').get_text()\n",
    "    # get rid of multiple whitespaces and \\n\n",
    "    product_title = re.sub(r'\\s+', ' ', product_title).strip()\n",
    "\n",
    "    # --------------------- product price ---------------------\n",
    "\n",
    "    # product_price = product_soup.find('p', class_='product-new-price').get_text()\n",
    "    # # get rid of ' Lei'\n",
    "    # product_price = product_price[:-4] \n",
    "    # # transform string '1.920,00' to float '1920.0'\n",
    "    # product_price = float(product_price.replace('.', '').replace(',', '.')) \n",
    "\n",
    "    # ^^^^^ this approach got dumped\n",
    "\n",
    "    # used this approach instead of looking through the HTML tags (like above)\n",
    "    # because formats were too many, e.g. 'de la xxx.xx Lei' when multiple offers exist\n",
    "\n",
    "    scripts = product_soup.find_all('script')\n",
    "    for script in scripts:\n",
    "        if 'EM.product_id' in script.text:\n",
    "            product_id_search = re.search(r'EM.productDiscountedPrice\\s=\\s([0-9.]+);', script.text)\n",
    "            if product_id_search:\n",
    "                product_price = float(product_id_search.group(1))\n",
    "                break\n",
    "\n",
    "    # --------------------- get reviews ---------------------\n",
    "\n",
    "    review_titles_arr = []\n",
    "    review_ratings_arr = []\n",
    "    review_contents_arr = []\n",
    "    review_verified_users_arr = []\n",
    "\n",
    "    while offset < reviews_number:\n",
    "        params = {\n",
    "            \"source_id\": 7,\n",
    "            \"page[limit]\": 10,\n",
    "            \"page[offset]\": offset,\n",
    "            \"sort[created]\": \"desc\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(endpoint_url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        items = data['reviews']['items']\n",
    "\n",
    "        review_titles = [item['title'] for item in items]\n",
    "        review_ratings = [item['rating'] for item in items]\n",
    "        review_contents = [item['content'] for item in items]\n",
    "        review_verified_users = [item['is_bought'] for item in items]\n",
    "\n",
    "        review_titles_arr += review_titles\n",
    "        review_ratings_arr += review_ratings\n",
    "        review_contents_arr += review_contents\n",
    "        review_verified_users_arr += review_verified_users\n",
    "\n",
    "        offset += 10\n",
    "\n",
    "    # --------------------- final product array ---------------------\n",
    "\n",
    "    merged_list = [\n",
    "        {\n",
    "            'product_title': product_title,\n",
    "            'product_price': product_price,\n",
    "            'review_title': review_title, \n",
    "            'review_rating': review_rating, \n",
    "            'review_verified_buyer': review_verified_buyer, \n",
    "            'review_content': review_content\n",
    "        }\n",
    "        for review_title, review_content, review_rating, review_verified_buyer in zip(review_titles_arr, review_contents_arr, review_ratings_arr, review_verified_users_arr)\n",
    "    ]\n",
    "\n",
    "    return merged_list\n",
    "\n",
    "# product_reviews = get_reviews_by_url('https://www.emag.ro/mouse-wireless-logitech-mx-master-3s-performance-8000-dpi-silent-usb-bt-graphite-910-006559/pd/DZMBWVMBM/')\n",
    "# for review in product_reviews:\n",
    "#     print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- get current listings' indices ---------------------\n",
    "\n",
    "def get_current_listings(url):\n",
    "    page_response = requests.get(url)\n",
    "    page_html = page_response.text\n",
    "    page_soup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        listings = page_soup.find('div', class_='control-label small hidden-xs hidden-sm js-listing-pagination').get_text()\n",
    "    except AttributeError:\n",
    "        return [-1, -1]\n",
    "\n",
    "    if listings is not None:\n",
    "        # Define the pattern to match the numbers, like:\n",
    "        # '1 - 5 din 5 produse'\n",
    "        # '1 - 60 din 262 de produse'\n",
    "        pattern = r'(\\d+)\\D+(\\d+)\\D+(\\d+)'\n",
    "\n",
    "        # Extract the numbers from input1\n",
    "        match1 = re.search(pattern, listings)\n",
    "        k1 = int(match1.group(1))\n",
    "        k2 = int(match1.group(2))\n",
    "\n",
    "        return [k1, k2]\n",
    "    \n",
    "\n",
    "# --------------------- get the total number of listings for the current search ---------------------    \n",
    "\n",
    "def get_total_listings(url):\n",
    "    page_response = requests.get(url)\n",
    "    page_html = page_response.text\n",
    "    page_soup = BeautifulSoup(page_html, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        listings = page_soup.find('div', class_='control-label small hidden-xs hidden-sm js-listing-pagination').get_text()\n",
    "    except AttributeError:\n",
    "        return -1\n",
    "\n",
    "    if listings is not None:\n",
    "        # Define the pattern to match the numbers, like:\n",
    "        # '1 - 5 din 5 produse'\n",
    "        # '1 - 60 din 262 de produse'\n",
    "        pattern = r'(\\d+)\\D+(\\d+)\\D+(\\d+)'\n",
    "\n",
    "        # Extract the numbers from input1\n",
    "        match1 = re.search(pattern, listings)\n",
    "        k = int(match1.group(3))\n",
    "\n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- get current listings' URLs ---------------------\n",
    "\n",
    "def get_product_links(url):\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    product_links = soup.find_all('a', class_='card-v2-title semibold mrg-btm-xxs js-product-url')    \n",
    "\n",
    "    return product_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# --------------------- main function for getting all reviews for all search results ---------------------\n",
    "\n",
    "def get_total_reviews(url):\n",
    "    total_reviews = []\n",
    "    total_products = get_total_listings(url)\n",
    "    print(f\"total products: {total_products}\")\n",
    "\n",
    "    if total_products > 0:\n",
    "        rounds = math.ceil(float(total_products / 60))\n",
    "        print(f\"rounds: {rounds}\")\n",
    "\n",
    "        k = 0\n",
    "        page_number = 1\n",
    "        final_url = url\n",
    "\n",
    "        [from_product, to_product] = get_current_listings(url)\n",
    "\n",
    "        for i in range(rounds):\n",
    "            print(f\"from: {from_product}, to: {to_product}, total: {total_products}\")\n",
    "            product_links = get_product_links(final_url)\n",
    "\n",
    "            if i == rounds - 1:\n",
    "                # facem de total % 60 ori\n",
    "                limit = total_products % 60\n",
    "            else:\n",
    "                # facem de 60 de ori\n",
    "                limit = 60\n",
    "\n",
    "            for j, item in enumerate(product_links):\n",
    "                if j >= limit:\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"getting reviews for {item['href']}\")\n",
    "                    total_reviews += get_reviews_by_url(item['href'])\n",
    "\n",
    "            page_number += 1\n",
    "            \n",
    "            final_url = f'{url}p{page_number}'\n",
    "            [from_product, to_product] = get_current_listings(final_url)\n",
    "            \n",
    "\n",
    "\n",
    "    return total_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.emag.ro/search/monitor dell/' # 140 rez\n",
    "# url = 'https://www.emag.ro/search/monitor benq/' # 81 rez\n",
    "url = 'https://www.emag.ro/search/sony xm5/' # 3 rez\n",
    "# url = 'https://www.emag.ro/search/iphone 14 pro max/p1' # 108 rez\n",
    "# url = 'https://www.emag.ro/search/macbook pro stand lemn maro negru/'\n",
    "    # MUST HAVE / AT END!!!!!\n",
    "\n",
    "reviews = get_total_reviews(url)\n",
    "\n",
    "if reviews is not None:\n",
    "    for review in reviews:\n",
    "        print(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file = 'reviews_output.csv'\n",
    "\n",
    "header = reviews[0].keys()\n",
    "\n",
    "with open(csv_file, 'w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(reviews)\n",
    "\n",
    "print(f\"Data has been written to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file = 'reviews_output.csv'\n",
    "\n",
    "# Define the column names and their respective data types\n",
    "column_names = ['product_title', 'product_price', 'review_title', 'review_rating', 'review_verified_buyer', 'review_content']\n",
    "column_types = {'product_title': str, 'product_price': float, 'review_title': str, 'review_rating': int, 'review_verified_buyer': bool, 'review_content': str}\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file, names=column_names, dtype=column_types, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install demoji\n",
    "%pip install nltk\n",
    "%pip install googletrans\n",
    "%pip install deepl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- TRANSLATE TO ENGLISH ---------------------\n",
    "\n",
    "import deepl\n",
    "\n",
    "auth_key = \"a25f32ec-b831-8e00-7f0a-e0d2f6fc6a4b:fx\"  # Replace with your key\n",
    "translator = deepl.Translator(auth_key)\n",
    "\n",
    "def translate_to_english(text):\n",
    "    result = translator.translate_text(text, source_lang=\"RO\", target_lang=\"EN-US\")\n",
    "    return str(result)\n",
    "\n",
    "\n",
    "# # Print the updated DataFrame\n",
    "# print(df[['review_content', 'review_content_en']])\n",
    "\n",
    "# output_file = 'translated_output.csv'\n",
    "\n",
    "# df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR CONTENT\n",
    "\n",
    "df['review_content_en'] = df['review_content'].apply(translate_to_english)\n",
    "df = df.drop('review_content', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TITLE\n",
    "df['review_title_en'] = df['review_title'].apply(translate_to_english)\n",
    "df = df.drop('review_title', axis=1)\n",
    "\n",
    "output_file = 'translated_output.csv'\n",
    "\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- 2. Second Topic: Sentiment Analysis ---------------------\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create a SentimentIntensityAnalyzer object\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Perform sentiment analysis on 'review_content_en' column\n",
    "df['sentiment_score'] = df['review_content_en'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n",
    "\n",
    "# Classify sentiments based on the sentiment score\n",
    "df['sentiment_label'] = df['sentiment_score'].apply(lambda x: 'Positive' if x >= 0 else 'Negative')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df[['review_content_en', 'sentiment_score', 'sentiment_label']])\n",
    "\n",
    "output_file = 'sentiment_output.csv'\n",
    "\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/roberthevesi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/roberthevesi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# --------------------- 3. Third Topic: Data Cleaning & Preprocessing ---------------------\n",
    "\n",
    "import html\n",
    "import string\n",
    "import unicodedata\n",
    "import demoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to remove miscellaneous characters\n",
    "# def remove_miscellaneous_chars(text):\n",
    "#     if isinstance(text, str):\n",
    "#         # Update the regular expression pattern to not remove hyphens inside words\n",
    "#         cleaned_text = re.sub(r\"([^\\w\\s-]|(?<!\\w)-(?!\\w))\", \"\", text)\n",
    "#         return cleaned_text\n",
    "#     return text\n",
    "\n",
    "# # Function to remove emojis\n",
    "# def remove_emojis(text):\n",
    "#     if isinstance(text, str):\n",
    "#         cleaned_text = demoji.replace(text, \"\")\n",
    "#         return cleaned_text\n",
    "#     return text\n",
    "\n",
    "# # Function to remove HTML tags\n",
    "# def remove_html_tags(text):\n",
    "#     if isinstance(text, str):\n",
    "#         cleaned_text = re.sub(r\"<.*?>\", \"\", text)\n",
    "#         return cleaned_text\n",
    "#     return text\n",
    "\n",
    "\n",
    "# Function for text normalization, stemming, and stop word removal\n",
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))  # Update the language if necessary\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Perform stemming\n",
    "    # stemmer = PorterStemmer()\n",
    "    # tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         product_title  product_price  \\\n",
      "0    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "1    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "2    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "3    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "4    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "..                                                 ...            ...   \n",
      "136  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "137  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "138  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "139  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "140  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "\n",
      "                         review_title  review_rating  review_verified_buyer  \\\n",
      "0                      foart multumit              5                   True   \n",
      "1                               excel              5                  False   \n",
      "2                         nu recomand              1                   True   \n",
      "3                     foart multumita              5                   True   \n",
      "4                               excel              5                  False   \n",
      "..                                ...            ...                    ...   \n",
      "136                    foart multumit              5                   True   \n",
      "137  de la xm la xm trecand prin bose              4                   True   \n",
      "138                        acceptabil              3                   True   \n",
      "139                       e ce trebui              5                  False   \n",
      "140                         nu merita              2                  False   \n",
      "\n",
      "                                     review_content_en  \n",
      "0    gift son plea told like better appl airpod max...  \n",
      "1      good week right earphon fell couldnt hear thing  \n",
      "2    matt paint headphon start peel ive month taken...  \n",
      "3             plea headphon exact needbr deliveri fast  \n",
      "4    expect everi way noi reduct function work much...  \n",
      "..                                                 ...  \n",
      "136  great sound except especi play equal qualiti d...  \n",
      "137  putin context purcha headphon upgrad soni xm w...  \n",
      "138  audio experi good compar xm xm come close airp...  \n",
      "139  wouldnt consid audiophil say enjoy listen musi...  \n",
      "140  im compar bose market coupl year bose qc ii pa...  \n",
      "\n",
      "[141 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         product_title  product_price  \\\n",
      "0    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "1    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "2    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "3    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "4    Casti Over the Ear Sony WH-1000XM5B, Wireless,...        1799.99   \n",
      "..                                                 ...            ...   \n",
      "136  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "137  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "138  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "139  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "140  Casti Over the Ear Sony WH-1000XM5S, Wireless,...        1799.99   \n",
      "\n",
      "                         review_title  review_rating  review_verified_buyer  \\\n",
      "0                      foart multumit              5                   True   \n",
      "1                               excel              5                  False   \n",
      "2                         nu recomand              1                   True   \n",
      "3                     foart multumita              5                   True   \n",
      "4                               excel              5                  False   \n",
      "..                                ...            ...                    ...   \n",
      "136                    foart multumit              5                   True   \n",
      "137  de la xm la xm trecand prin bose              4                   True   \n",
      "138                        acceptabil              3                   True   \n",
      "139                       e ce trebui              5                  False   \n",
      "140                         nu merita              2                  False   \n",
      "\n",
      "                                     review_content_en  \n",
      "0    gift son plea told like better appl airpod max...  \n",
      "1      good week right earphon fell couldnt hear thing  \n",
      "2    matt paint headphon start peel ive month taken...  \n",
      "3             plea headphon exact needbr deliveri fast  \n",
      "4    expect everi way noi reduct function work much...  \n",
      "..                                                 ...  \n",
      "136  great sound except especi play equal qualiti d...  \n",
      "137  putin context purcha headphon upgrad soni xm w...  \n",
      "138  audio experi good compar xm xm come close airp...  \n",
      "139  wouldnt consid audiophil say enjoy listen musi...  \n",
      "140  im compar bose market coupl year bose qc ii pa...  \n",
      "\n",
      "[141 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Apply data cleaning and preprocessing\n",
    "\n",
    "\n",
    "df['review_title'] = df['review_title'].apply(remove_miscellaneous_chars)\n",
    "df['review_title'] = df['review_title'].apply(remove_emojis)\n",
    "df['review_title'] = df['review_title'].apply(remove_html_tags)\n",
    "df['review_title'] = df['review_title'].apply(preprocess_text)\n",
    "\n",
    "df['review_content_en'] = df['review_content_en'].apply(remove_miscellaneous_chars)\n",
    "df['review_content_en'] = df['review_content_en'].apply(remove_emojis)\n",
    "df['review_content_en'] = df['review_content_en'].apply(remove_html_tags)\n",
    "df['review_content_en'] = df['review_content_en'].apply(preprocess_text)\n",
    "\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n",
    "\n",
    "output_file = 'cleaned_output.csv'\n",
    "\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert 'review_content_en' column to string type\n",
    "df['review_content_en'] = df['review_content_en'].astype(str)\n",
    "\n",
    "# Create an instance of TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the 'review_content_en' column using TF-IDF\n",
    "tfidf_matrix = tfidf.fit_transform(df['review_content_en'])\n",
    "\n",
    "# Create a DataFrame from the TF-IDF matrix\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# Print the TF-IDF DataFrame\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# # Create an instance of TfidfVectorizer\n",
    "# tfidf = TfidfVectorizer()\n",
    "\n",
    "# # Fit and transform the 'review_content' column using TF-IDF\n",
    "# tfidf_matrix = tfidf.fit_transform(df['review_content_en'])\n",
    "\n",
    "# # Calculate cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Choose the number of sentences to include in the summary\n",
    "num_sentences = 3\n",
    "\n",
    "# Generate summaries for each review\n",
    "summaries = []\n",
    "for i, row in df.iterrows():\n",
    "    review = row['review_content_en']\n",
    "    sentence_scores = [(sentence, cosine_sim[i].mean()) for sentence in review.split('.')]\n",
    "    sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    summary = ' '.join([sentence_score[0] for sentence_score in sentence_scores[:num_sentences]])\n",
    "    summaries.append(summary)\n",
    "\n",
    "# Add the summaries to the DataFrame\n",
    "df['summary'] = summaries\n",
    "\n",
    "# Print the DataFrame with summaries\n",
    "text_file = 'test.txt'\n",
    "\n",
    "# Export the DataFrame to a text file\n",
    "df.to_csv(text_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Preprocess the text\n",
    "documents = df['review_content_en'].apply(simple_preprocess)\n",
    "\n",
    "# Create a dictionary representation of the documents\n",
    "dictionary = Dictionary(documents)\n",
    "\n",
    "# Create a Bag-of-Words representation of the documents\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "# Build the LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, random_state=42)\n",
    "\n",
    "# Print the topics and their top keywords\n",
    "for topic_id, topic_keywords in lda_model.print_topics():\n",
    "    print(f'Topic {topic_id + 1}: {topic_keywords}')\n",
    "\n",
    "# Calculate the coherence score\n",
    "coherence_model = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "print(f'Coherence Score: {coherence_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm_project",
   "language": "python",
   "name": "dm_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
